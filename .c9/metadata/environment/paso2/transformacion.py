{"filter":false,"title":"transformacion.py","tooltip":"/paso2/transformacion.py","undoManager":{"mark":31,"position":31,"stack":[[{"start":{"row":0,"column":0},"end":{"row":61,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","","def lambda_handler(event, context):","    s3_client = boto3.client(\"s3\")","    bucket_name = \"paginaspruebas\"","    target_bucket = \"casas-final-xxx\"","    ","    # Extraer el nombre del archivo desde el evento","    for record in event['Records']:","        s3_object = record['s3']['object']['key']","        print(f\"Procesando archivo: {s3_object}\")","        ","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_name, Key=s3_object)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Guardar los datos en CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = f\"{csv_filename}\"","        ","        csv_data = \"FechaDescarga,Barrio,Valor,NumHabitaciones,NumBanos,mts2\\n\"","        csv_data += \"\\n\".join([\"\",\"\".join(row) for row in casas])","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_data,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","    return {","        \"statusCode\": 200,","        \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","    }",""],"id":32}],[{"start":{"row":0,"column":0},"end":{"row":61,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","","def lambda_handler(event, context):","    s3_client = boto3.client(\"s3\")","    bucket_name = \"paginaspruebas\"","    target_bucket = \"casas-final-xxx\"","    ","    # Extraer el nombre del archivo desde el evento","    for record in event['Records']:","        s3_object = record['s3']['object']['key']","        print(f\"Procesando archivo: {s3_object}\")","        ","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_name, Key=s3_object)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Guardar los datos en CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = f\"{csv_filename}\"","        ","        csv_data = \"FechaDescarga,Barrio,Valor,NumHabitaciones,NumBanos,mts2\\n\"","        csv_data += \"\\n\".join([\"\",\"\".join(row) for row in casas])","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_data,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","    return {","        \"statusCode\": 200,","        \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","    }",""],"id":33},{"start":{"row":0,"column":0},"end":{"row":53,"column":4},"action":"insert","lines":["import boto3","import csv","import datetime","from bs4 import BeautifulSoup","","","s3_client = boto3.client(\"s3\")","BUCKET_DESTINO = \"casas-final-mitula\"","","","def app(event, context):","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo_html = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Procesando archivo: {archivo_html} desde {bucket_origen}\")","    ","    response = s3_client.get_object(Bucket=bucket_origen, Key=archivo_html)","    contenido_html = response[\"Body\"].read().decode(\"utf-8\")","    ","    soup = BeautifulSoup(contenido_html, \"html.parser\")","    ","    casas = []","","","    for card in soup.find_all(\"a\", class_=\"listing listing-card\"):","        data = {","            \"FechaDescarga\": datetime.datetime.now().strftime(\"%Y-%m-%d\"), ","            \"Barrio\": card.get(\"data-location\"),","            \"Valor\": card.get(\"data-price\"),","            \"NumHabitaciones\": card.get(\"data-rooms\"),","            \"NumBanos\": card.find(\"p\", {\"data-test\": \"bathrooms\"}).get(\"content\") if card.find(\"p\", {\"data-test\": \"bathrooms\"}) else None,","            \"mts2\": card.get(\"data-floorarea\"),","        }","        casas.append(data)","    ","    fecha_hoy = datetime.datetime.now().strftime(\"%Y-%m-%d\")","    name_file = archivo_html.replace(\".html\", \"\")","    nombre_csv = f\"{name_file}.csv\"","    ruta_csv = f\"/tmp/{nombre_csv}\"  ","","    ","    with open(ruta_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:","        campos = ['FechaDescarga', 'Barrio', 'Valor', 'NumHabitaciones', 'NumBanos', 'mts2']","        writer = csv.DictWriter(csvfile, fieldnames=campos, delimiter=';')","        ","        writer.writeheader()","        writer.writerows(casas)","","    ","    s3_client.upload_file(ruta_csv, BUCKET_DESTINO, f\"{fecha_hoy}/{nombre_csv}\")","","    print(f\"Archivo CSV subido: s3://{BUCKET_DESTINO}/{fecha_hoy}/{nombre_csv}\")","    ","    return {}","    "]}],[{"start":{"row":7,"column":18},"end":{"row":7,"column":36},"action":"remove","lines":["casas-final-mitula"],"id":34}],[{"start":{"row":7,"column":18},"end":{"row":7,"column":19},"action":"insert","lines":["p"],"id":35},{"start":{"row":7,"column":19},"end":{"row":7,"column":20},"action":"insert","lines":["a"]},{"start":{"row":7,"column":20},"end":{"row":7,"column":21},"action":"insert","lines":["g"]},{"start":{"row":7,"column":21},"end":{"row":7,"column":22},"action":"insert","lines":["i"]},{"start":{"row":7,"column":22},"end":{"row":7,"column":23},"action":"insert","lines":["n"]},{"start":{"row":7,"column":23},"end":{"row":7,"column":24},"action":"insert","lines":["a"]},{"start":{"row":7,"column":24},"end":{"row":7,"column":25},"action":"insert","lines":["s"]},{"start":{"row":7,"column":25},"end":{"row":7,"column":26},"action":"insert","lines":["p"]},{"start":{"row":7,"column":26},"end":{"row":7,"column":27},"action":"insert","lines":["r"]}],[{"start":{"row":7,"column":27},"end":{"row":7,"column":28},"action":"insert","lines":["u"],"id":36},{"start":{"row":7,"column":28},"end":{"row":7,"column":29},"action":"insert","lines":["e"]},{"start":{"row":7,"column":29},"end":{"row":7,"column":30},"action":"insert","lines":["b"]},{"start":{"row":7,"column":30},"end":{"row":7,"column":31},"action":"insert","lines":["a"]},{"start":{"row":7,"column":31},"end":{"row":7,"column":32},"action":"insert","lines":["s"]}],[{"start":{"row":0,"column":0},"end":{"row":53,"column":4},"action":"remove","lines":["import boto3","import csv","import datetime","from bs4 import BeautifulSoup","","","s3_client = boto3.client(\"s3\")","BUCKET_DESTINO = \"paginaspruebas\"","","","def app(event, context):","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo_html = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Procesando archivo: {archivo_html} desde {bucket_origen}\")","    ","    response = s3_client.get_object(Bucket=bucket_origen, Key=archivo_html)","    contenido_html = response[\"Body\"].read().decode(\"utf-8\")","    ","    soup = BeautifulSoup(contenido_html, \"html.parser\")","    ","    casas = []","","","    for card in soup.find_all(\"a\", class_=\"listing listing-card\"):","        data = {","            \"FechaDescarga\": datetime.datetime.now().strftime(\"%Y-%m-%d\"), ","            \"Barrio\": card.get(\"data-location\"),","            \"Valor\": card.get(\"data-price\"),","            \"NumHabitaciones\": card.get(\"data-rooms\"),","            \"NumBanos\": card.find(\"p\", {\"data-test\": \"bathrooms\"}).get(\"content\") if card.find(\"p\", {\"data-test\": \"bathrooms\"}) else None,","            \"mts2\": card.get(\"data-floorarea\"),","        }","        casas.append(data)","    ","    fecha_hoy = datetime.datetime.now().strftime(\"%Y-%m-%d\")","    name_file = archivo_html.replace(\".html\", \"\")","    nombre_csv = f\"{name_file}.csv\"","    ruta_csv = f\"/tmp/{nombre_csv}\"  ","","    ","    with open(ruta_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:","        campos = ['FechaDescarga', 'Barrio', 'Valor', 'NumHabitaciones', 'NumBanos', 'mts2']","        writer = csv.DictWriter(csvfile, fieldnames=campos, delimiter=';')","        ","        writer.writeheader()","        writer.writerows(casas)","","    ","    s3_client.upload_file(ruta_csv, BUCKET_DESTINO, f\"{fecha_hoy}/{nombre_csv}\")","","    print(f\"Archivo CSV subido: s3://{BUCKET_DESTINO}/{fecha_hoy}/{nombre_csv}\")","    ","    return {}","    "],"id":37},{"start":{"row":0,"column":0},"end":{"row":77,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"casas-final-xxx\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Guardar los datos en CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = f\"{csv_filename}\"","        ","        csv_data = \"FechaDescarga,Barrio,Valor,NumHabitaciones,NumBanos,mts2\\n\"","        csv_data += \"\\n\".join([\"\",\"\".join(row) for row in casas])","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_data,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":0,"column":0},"end":{"row":77,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"casas-final-xxx\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Guardar los datos en CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = f\"{csv_filename}\"","        ","        csv_data = \"FechaDescarga,Barrio,Valor,NumHabitaciones,NumBanos,mts2\\n\"","        csv_data += \"\\n\".join([\"\",\"\".join(row) for row in casas])","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_data,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":38},{"start":{"row":0,"column":0},"end":{"row":53,"column":4},"action":"insert","lines":["import boto3","import csv","import datetime","from bs4 import BeautifulSoup","","","s3_client = boto3.client(\"s3\")","BUCKET_DESTINO = \"casas-final-mitula\"","","","def app(event, context):","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo_html = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Procesando archivo: {archivo_html} desde {bucket_origen}\")","    ","    response = s3_client.get_object(Bucket=bucket_origen, Key=archivo_html)","    contenido_html = response[\"Body\"].read().decode(\"utf-8\")","    ","    soup = BeautifulSoup(contenido_html, \"html.parser\")","    ","    casas = []","","","    for card in soup.find_all(\"a\", class_=\"listing listing-card\"):","        data = {","            \"FechaDescarga\": datetime.datetime.now().strftime(\"%Y-%m-%d\"), ","            \"Barrio\": card.get(\"data-location\"),","            \"Valor\": card.get(\"data-price\"),","            \"NumHabitaciones\": card.get(\"data-rooms\"),","            \"NumBanos\": card.find(\"p\", {\"data-test\": \"bathrooms\"}).get(\"content\") if card.find(\"p\", {\"data-test\": \"bathrooms\"}) else None,","            \"mts2\": card.get(\"data-floorarea\"),","        }","        casas.append(data)","    ","    fecha_hoy = datetime.datetime.now().strftime(\"%Y-%m-%d\")","    name_file = archivo_html.replace(\".html\", \"\")","    nombre_csv = f\"{name_file}.csv\"","    ruta_csv = f\"/tmp/{nombre_csv}\"  ","","    ","    with open(ruta_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:","        campos = ['FechaDescarga', 'Barrio', 'Valor', 'NumHabitaciones', 'NumBanos', 'mts2']","        writer = csv.DictWriter(csvfile, fieldnames=campos, delimiter=';')","        ","        writer.writeheader()","        writer.writerows(casas)","","    ","    s3_client.upload_file(ruta_csv, BUCKET_DESTINO, f\"{fecha_hoy}/{nombre_csv}\")","","    print(f\"Archivo CSV subido: s3://{BUCKET_DESTINO}/{fecha_hoy}/{nombre_csv}\")","    ","    return {}","    "]}],[{"start":{"row":7,"column":24},"end":{"row":7,"column":29},"action":"remove","lines":["final"],"id":39},{"start":{"row":7,"column":23},"end":{"row":7,"column":24},"action":"remove","lines":["-"]},{"start":{"row":7,"column":22},"end":{"row":7,"column":23},"action":"remove","lines":["s"]}],[{"start":{"row":7,"column":22},"end":{"row":7,"column":23},"action":"remove","lines":["-"],"id":40},{"start":{"row":7,"column":22},"end":{"row":7,"column":23},"action":"remove","lines":["m"]}],[{"start":{"row":7,"column":21},"end":{"row":7,"column":22},"action":"remove","lines":["a"],"id":41},{"start":{"row":7,"column":20},"end":{"row":7,"column":21},"action":"remove","lines":["s"]}],[{"start":{"row":7,"column":18},"end":{"row":7,"column":25},"action":"remove","lines":["caitula"],"id":42},{"start":{"row":7,"column":18},"end":{"row":7,"column":19},"action":"insert","lines":["p"]},{"start":{"row":7,"column":19},"end":{"row":7,"column":20},"action":"insert","lines":["r"]},{"start":{"row":7,"column":20},"end":{"row":7,"column":21},"action":"insert","lines":["u"]},{"start":{"row":7,"column":21},"end":{"row":7,"column":22},"action":"insert","lines":["e"]}],[{"start":{"row":7,"column":21},"end":{"row":7,"column":22},"action":"remove","lines":["e"],"id":43},{"start":{"row":7,"column":20},"end":{"row":7,"column":21},"action":"remove","lines":["u"]},{"start":{"row":7,"column":19},"end":{"row":7,"column":20},"action":"remove","lines":["r"]},{"start":{"row":7,"column":18},"end":{"row":7,"column":19},"action":"remove","lines":["p"]}],[{"start":{"row":7,"column":18},"end":{"row":7,"column":19},"action":"insert","lines":["p"],"id":44},{"start":{"row":7,"column":19},"end":{"row":7,"column":20},"action":"insert","lines":["a"]},{"start":{"row":7,"column":20},"end":{"row":7,"column":21},"action":"insert","lines":["g"]},{"start":{"row":7,"column":21},"end":{"row":7,"column":22},"action":"insert","lines":["i"]},{"start":{"row":7,"column":22},"end":{"row":7,"column":23},"action":"insert","lines":["n"]},{"start":{"row":7,"column":23},"end":{"row":7,"column":24},"action":"insert","lines":["a"]},{"start":{"row":7,"column":24},"end":{"row":7,"column":25},"action":"insert","lines":["s"]},{"start":{"row":7,"column":25},"end":{"row":7,"column":26},"action":"insert","lines":["p"]}],[{"start":{"row":7,"column":26},"end":{"row":7,"column":27},"action":"insert","lines":["r"],"id":45},{"start":{"row":7,"column":27},"end":{"row":7,"column":28},"action":"insert","lines":["u"]},{"start":{"row":7,"column":28},"end":{"row":7,"column":29},"action":"insert","lines":["e"]},{"start":{"row":7,"column":29},"end":{"row":7,"column":30},"action":"insert","lines":["b"]},{"start":{"row":7,"column":30},"end":{"row":7,"column":31},"action":"insert","lines":["a"]},{"start":{"row":7,"column":31},"end":{"row":7,"column":32},"action":"insert","lines":["s"]}],[{"start":{"row":0,"column":0},"end":{"row":53,"column":4},"action":"remove","lines":["import boto3","import csv","import datetime","from bs4 import BeautifulSoup","","","s3_client = boto3.client(\"s3\")","BUCKET_DESTINO = \"paginaspruebas\"","","","def app(event, context):","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo_html = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Procesando archivo: {archivo_html} desde {bucket_origen}\")","    ","    response = s3_client.get_object(Bucket=bucket_origen, Key=archivo_html)","    contenido_html = response[\"Body\"].read().decode(\"utf-8\")","    ","    soup = BeautifulSoup(contenido_html, \"html.parser\")","    ","    casas = []","","","    for card in soup.find_all(\"a\", class_=\"listing listing-card\"):","        data = {","            \"FechaDescarga\": datetime.datetime.now().strftime(\"%Y-%m-%d\"), ","            \"Barrio\": card.get(\"data-location\"),","            \"Valor\": card.get(\"data-price\"),","            \"NumHabitaciones\": card.get(\"data-rooms\"),","            \"NumBanos\": card.find(\"p\", {\"data-test\": \"bathrooms\"}).get(\"content\") if card.find(\"p\", {\"data-test\": \"bathrooms\"}) else None,","            \"mts2\": card.get(\"data-floorarea\"),","        }","        casas.append(data)","    ","    fecha_hoy = datetime.datetime.now().strftime(\"%Y-%m-%d\")","    name_file = archivo_html.replace(\".html\", \"\")","    nombre_csv = f\"{name_file}.csv\"","    ruta_csv = f\"/tmp/{nombre_csv}\"  ","","    ","    with open(ruta_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:","        campos = ['FechaDescarga', 'Barrio', 'Valor', 'NumHabitaciones', 'NumBanos', 'mts2']","        writer = csv.DictWriter(csvfile, fieldnames=campos, delimiter=';')","        ","        writer.writeheader()","        writer.writerows(casas)","","    ","    s3_client.upload_file(ruta_csv, BUCKET_DESTINO, f\"{fecha_hoy}/{nombre_csv}\")","","    print(f\"Archivo CSV subido: s3://{BUCKET_DESTINO}/{fecha_hoy}/{nombre_csv}\")","    ","    return {}","    "],"id":46},{"start":{"row":0,"column":0},"end":{"row":77,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"casas-final-xxx\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Guardar los datos en CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_data = \"FechaDescarga,Barrio,Valor,NumHabitaciones,NumBanos,mts2\\n\"","        csv_data += \"\\n\".join([\"\",\"\".join(map(str, row)) for row in casas])","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_data,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":22,"column":27},"end":{"row":22,"column":32},"action":"remove","lines":["final"],"id":47}],[{"start":{"row":22,"column":27},"end":{"row":22,"column":28},"action":"remove","lines":["-"],"id":48}],[{"start":{"row":22,"column":26},"end":{"row":22,"column":27},"action":"remove","lines":["-"],"id":49},{"start":{"row":22,"column":25},"end":{"row":22,"column":26},"action":"remove","lines":["s"]},{"start":{"row":22,"column":24},"end":{"row":22,"column":25},"action":"remove","lines":["a"]},{"start":{"row":22,"column":23},"end":{"row":22,"column":24},"action":"remove","lines":["s"]},{"start":{"row":22,"column":22},"end":{"row":22,"column":23},"action":"remove","lines":["a"]},{"start":{"row":22,"column":21},"end":{"row":22,"column":22},"action":"remove","lines":["c"]}],[{"start":{"row":22,"column":21},"end":{"row":22,"column":22},"action":"remove","lines":["x"],"id":50},{"start":{"row":22,"column":21},"end":{"row":22,"column":22},"action":"remove","lines":["x"]},{"start":{"row":22,"column":21},"end":{"row":22,"column":22},"action":"remove","lines":["x"]}],[{"start":{"row":22,"column":21},"end":{"row":22,"column":22},"action":"insert","lines":["p"],"id":51},{"start":{"row":22,"column":22},"end":{"row":22,"column":23},"action":"insert","lines":["a"]},{"start":{"row":22,"column":23},"end":{"row":22,"column":24},"action":"insert","lines":["g"]},{"start":{"row":22,"column":24},"end":{"row":22,"column":25},"action":"insert","lines":["i"]},{"start":{"row":22,"column":25},"end":{"row":22,"column":26},"action":"insert","lines":["n"]},{"start":{"row":22,"column":26},"end":{"row":22,"column":27},"action":"insert","lines":["a"]},{"start":{"row":22,"column":27},"end":{"row":22,"column":28},"action":"insert","lines":["s"]},{"start":{"row":22,"column":28},"end":{"row":22,"column":29},"action":"insert","lines":["p"]},{"start":{"row":22,"column":29},"end":{"row":22,"column":30},"action":"insert","lines":["r"]},{"start":{"row":22,"column":30},"end":{"row":22,"column":31},"action":"insert","lines":["u"]},{"start":{"row":22,"column":31},"end":{"row":22,"column":32},"action":"insert","lines":["e"]},{"start":{"row":22,"column":32},"end":{"row":22,"column":33},"action":"insert","lines":["b"]}],[{"start":{"row":22,"column":33},"end":{"row":22,"column":34},"action":"insert","lines":["a"],"id":52},{"start":{"row":22,"column":34},"end":{"row":22,"column":35},"action":"insert","lines":["s"]}],[{"start":{"row":55,"column":8},"end":{"row":55,"column":75},"action":"remove","lines":["csv_data += \"\\n\".join([\"\",\"\".join(map(str, row)) for row in casas])"],"id":53},{"start":{"row":55,"column":8},"end":{"row":56,"column":0},"action":"insert","lines":["csv_data += \"\\n\".join([\"\".join(map(str, row)) for row in casas])",""]}],[{"start":{"row":55,"column":72},"end":{"row":56,"column":0},"action":"remove","lines":["",""],"id":54}],[{"start":{"row":55,"column":0},"end":{"row":55,"column":72},"action":"remove","lines":["        csv_data += \"\\n\".join([\"\".join(map(str, row)) for row in casas])"],"id":55},{"start":{"row":55,"column":0},"end":{"row":56,"column":0},"action":"insert","lines":["csv_data += \"\\n\".join([\",\".join(map(str, row)) for row in casas])",""]}],[{"start":{"row":55,"column":0},"end":{"row":55,"column":4},"action":"insert","lines":["    "],"id":56}],[{"start":{"row":55,"column":4},"end":{"row":55,"column":8},"action":"insert","lines":["    "],"id":57}],[{"start":{"row":0,"column":0},"end":{"row":78,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Guardar los datos en CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_data = \"FechaDescarga,Barrio,Valor,NumHabitaciones,NumBanos,mts2\\n\"","        csv_data += \"\\n\".join([\",\".join(map(str, row)) for row in casas])","","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_data,","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":58},{"start":{"row":0,"column":0},"end":{"row":80,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Crear un buffer para escribir el CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])  # Encabezados","        csv_writer.writerows(casas)  # Escribir los datos","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_buffer.getvalue(),","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":0,"column":0},"end":{"row":80,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.select(\".listing-item\"):  # Ajustar según HTML real","            barrio = casa.select_one(\".location\").text.strip() if casa.select_one(\".location\") else \"N/A\"","            valor = casa.select_one(\".price\").text.strip() if casa.select_one(\".price\") else \"N/A\"","            num_habitaciones = casa.select_one(\".rooms\").text.strip() if casa.select_one(\".rooms\") else \"N/A\"","            num_banos = casa.select_one(\".bathrooms\").text.strip() if casa.select_one(\".bathrooms\") else \"N/A\"","            mts2 = casa.select_one(\".size\").text.strip() if casa.select_one(\".size\") else \"N/A\"","            ","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Crear un buffer para escribir el CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])  # Encabezados","        csv_writer.writerows(casas)  # Escribir los datos","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_buffer.getvalue(),","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":59},{"start":{"row":0,"column":0},"end":{"row":81,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.find_all(\"div\", class_=\"swiper-slide\"):  # Buscar cada \"swiper-slide\"","            barrio = casa.find(\"span\", class_=\"location\").text.strip() if casa.find(\"span\", class_=\"location\") else \"N/A\"","            valor = casa.find(\"span\", class_=\"price\").text.strip() if casa.find(\"span\", class_=\"price\") else \"N/A\"","            num_habitaciones = casa.find(\"span\", class_=\"rooms\").text.strip() if casa.find(\"span\", class_=\"rooms\") else \"N/A\"","            num_banos = casa.find(\"span\", class_=\"bathrooms\").text.strip() if casa.find(\"span\", class_=\"bathrooms\") else \"N/A\"","            mts2 = casa.find(\"span\", class_=\"size\").text.strip() if casa.find(\"span\", class_=\"size\") else \"N/A\"","            ","            # Almacenar los datos extraídos","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Crear un buffer para escribir el CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])  # Encabezados","        csv_writer.writerows(casas)  # Escribir los datos","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_buffer.getvalue(),","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":0,"column":0},"end":{"row":81,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos (ajustar los selectores según la estructura de la página)","        casas = []","        for casa in soup.find_all(\"div\", class_=\"swiper-slide\"):  # Buscar cada \"swiper-slide\"","            barrio = casa.find(\"span\", class_=\"location\").text.strip() if casa.find(\"span\", class_=\"location\") else \"N/A\"","            valor = casa.find(\"span\", class_=\"price\").text.strip() if casa.find(\"span\", class_=\"price\") else \"N/A\"","            num_habitaciones = casa.find(\"span\", class_=\"rooms\").text.strip() if casa.find(\"span\", class_=\"rooms\") else \"N/A\"","            num_banos = casa.find(\"span\", class_=\"bathrooms\").text.strip() if casa.find(\"span\", class_=\"bathrooms\") else \"N/A\"","            mts2 = casa.find(\"span\", class_=\"size\").text.strip() if casa.find(\"span\", class_=\"size\") else \"N/A\"","            ","            # Almacenar los datos extraídos","            casas.append([","                datetime.utcnow().strftime(\"%Y-%m-%d\"),","                barrio,","                valor,","                num_habitaciones,","                num_banos,","                mts2","            ])","        ","        # Crear un buffer para escribir el CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])  # Encabezados","        csv_writer.writerows(casas)  # Escribir los datos","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_buffer.getvalue(),","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":60},{"start":{"row":0,"column":0},"end":{"row":113,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos","        casas = []","        ","        # Buscar todas las tarjetas de propiedades","        for casa in soup.find_all(\"div\", class_=\"listing-card__content\"):","            try:","                # Título del apartamento","                titulo = casa.find(\"span\", class_=\"title\").text.strip() if casa.find(\"span\", class_=\"title\") else \"N/A\"","                ","                # Precio del apartamento","                precio = casa.find(\"span\", class_=\"price__actual\").text.strip() if casa.find(\"span\", class_=\"price__actual\") else \"N/A\"","                ","                # Ubicación","                ubicacion = casa.find(\"div\", class_=\"listing-card__location__geo\").text.strip() if casa.find(\"div\", class_=\"listing-card__location__geo\") else \"N/A\"","                ","                # Número de habitaciones","                habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bedrooms\"}) else \"N/A\"","                ","                # Número de baños","                banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bathrooms\"}) else \"N/A\"","                ","                # Tamaño del área","                area = casa.find(\"p\", {\"data-test\": \"floor-area\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"floor-area\"}) else \"N/A\"","                ","                # Instalaciones adicionales","                instalaciones = [facility.text.strip() for facility in casa.find_all(\"span\", class_=\"listing-card__facilities__facility\")]","                instalaciones = \", \".join(instalaciones) if instalaciones else \"N/A\"","                ","                # Fecha de publicación y agencia","                fecha_publicacion_agencia = casa.find(\"p\", class_=\"listing-card__information__bottom__published-date-and-agency\").text.strip() if casa.find(\"p\", class_=\"listing-card__information__bottom__published-date-and-agency\") else \"N/A\"","                ","                # Agregar todos los datos de la propiedad","                casas.append([","                    datetime.utcnow().strftime(\"%Y-%m-%d\"),","                    titulo,","                    precio,","                    ubicacion,","                    habitaciones,","                    banos,","                    area,","                    instalaciones,","                    fecha_publicacion_agencia","                ])","            ","            except Exception as e:","                print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                continue","        ","        if not casas:","            print(\"No se extrajeron datos de propiedades.\")","","        # Crear un buffer para escribir el CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        csv_writer.writerow([\"FechaDescarga\", \"Titulo\", \"Precio\", \"Ubicacion\", \"Habitaciones\", \"Banos\", \"Area\", \"Instalaciones\", \"FechaPublicacionAgencia\"])  # Encabezados","        csv_writer.writerows(casas)  # Escribir los datos","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_buffer.getvalue(),","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":0,"column":0},"end":{"row":113,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Extraer datos","        casas = []","        ","        # Buscar todas las tarjetas de propiedades","        for casa in soup.find_all(\"div\", class_=\"listing-card__content\"):","            try:","                # Título del apartamento","                titulo = casa.find(\"span\", class_=\"title\").text.strip() if casa.find(\"span\", class_=\"title\") else \"N/A\"","                ","                # Precio del apartamento","                precio = casa.find(\"span\", class_=\"price__actual\").text.strip() if casa.find(\"span\", class_=\"price__actual\") else \"N/A\"","                ","                # Ubicación","                ubicacion = casa.find(\"div\", class_=\"listing-card__location__geo\").text.strip() if casa.find(\"div\", class_=\"listing-card__location__geo\") else \"N/A\"","                ","                # Número de habitaciones","                habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bedrooms\"}) else \"N/A\"","                ","                # Número de baños","                banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bathrooms\"}) else \"N/A\"","                ","                # Tamaño del área","                area = casa.find(\"p\", {\"data-test\": \"floor-area\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"floor-area\"}) else \"N/A\"","                ","                # Instalaciones adicionales","                instalaciones = [facility.text.strip() for facility in casa.find_all(\"span\", class_=\"listing-card__facilities__facility\")]","                instalaciones = \", \".join(instalaciones) if instalaciones else \"N/A\"","                ","                # Fecha de publicación y agencia","                fecha_publicacion_agencia = casa.find(\"p\", class_=\"listing-card__information__bottom__published-date-and-agency\").text.strip() if casa.find(\"p\", class_=\"listing-card__information__bottom__published-date-and-agency\") else \"N/A\"","                ","                # Agregar todos los datos de la propiedad","                casas.append([","                    datetime.utcnow().strftime(\"%Y-%m-%d\"),","                    titulo,","                    precio,","                    ubicacion,","                    habitaciones,","                    banos,","                    area,","                    instalaciones,","                    fecha_publicacion_agencia","                ])","            ","            except Exception as e:","                print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                continue","        ","        if not casas:","            print(\"No se extrajeron datos de propiedades.\")","","        # Crear un buffer para escribir el CSV","        csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","        csv_key = csv_filename  # No se usa una carpeta","        ","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        csv_writer.writerow([\"FechaDescarga\", \"Titulo\", \"Precio\", \"Ubicacion\", \"Habitaciones\", \"Banos\", \"Area\", \"Instalaciones\", \"FechaPublicacionAgencia\"])  # Encabezados","        csv_writer.writerows(casas)  # Escribir los datos","        ","        # Subir CSV a S3","        s3_client.put_object(","            Bucket=target_bucket,","            Key=csv_key,","            Body=csv_buffer.getvalue(),","            ContentType=\"text/csv\"","        )","        print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":61},{"start":{"row":0,"column":0},"end":{"row":100,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Crear el buffer del CSV y el escritor","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        ","        # Escribir los encabezados","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])","        ","        # Extraer datos","        casas = []","        ","        # Buscar todas las tarjetas de propiedades","        for casa in soup.find_all(\"div\", class_=\"listing-card__content\"):","            try:","                # Fecha de descarga","                fecha_descarga = datetime.utcnow().strftime(\"%Y-%m-%d\")","                ","                # Barrio (Ubicación)","                barrio = casa.find(\"div\", class_=\"listing-card__location__geo\").text.strip() if casa.find(\"div\", class_=\"listing-card__location__geo\") else \"N/A\"","                ","                # Precio (Valor)","                valor = casa.find(\"span\", class_=\"price__actual\").text.strip() if casa.find(\"span\", class_=\"price__actual\") else \"N/A\"","                ","                # Número de habitaciones","                num_habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bedrooms\"}) else \"N/A\"","                ","                # Número de baños","                num_banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bathrooms\"}) else \"N/A\"","                ","                # Área (en mts²)","                mts2 = casa.find(\"p\", {\"data-test\": \"floor-area\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"floor-area\"}) else \"N/A\"","                ","                # Escribir la fila de datos en el buffer CSV","                csv_writer.writerow([fecha_descarga, barrio, valor, num_habitaciones, num_banos, mts2])","            ","            except Exception as e:","                print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                continue","        ","        # Subir el CSV a S3 solo si hay datos","        if csv_buffer.getvalue().strip():  # Comprobar que el buffer tiene datos","            # Nombre del archivo CSV","            csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","            csv_key = csv_filename  # No se usa una carpeta","            ","            # Subir el CSV a S3","            s3_client.put_object(","                Bucket=target_bucket,","                Key=csv_key,","                Body=csv_buffer.getvalue(),","                ContentType=\"text/csv\"","            )","            print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        else:","            print(\"No se extrajeron datos de propiedades.\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":0,"column":0},"end":{"row":100,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Crear el buffer del CSV y el escritor","        csv_buffer = io.StringIO()","        csv_writer = csv.writer(csv_buffer)","        ","        # Escribir los encabezados","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])","        ","        # Extraer datos","        casas = []","        ","        # Buscar todas las tarjetas de propiedades","        for casa in soup.find_all(\"div\", class_=\"listing-card__content\"):","            try:","                # Fecha de descarga","                fecha_descarga = datetime.utcnow().strftime(\"%Y-%m-%d\")","                ","                # Barrio (Ubicación)","                barrio = casa.find(\"div\", class_=\"listing-card__location__geo\").text.strip() if casa.find(\"div\", class_=\"listing-card__location__geo\") else \"N/A\"","                ","                # Precio (Valor)","                valor = casa.find(\"span\", class_=\"price__actual\").text.strip() if casa.find(\"span\", class_=\"price__actual\") else \"N/A\"","                ","                # Número de habitaciones","                num_habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bedrooms\"}) else \"N/A\"","                ","                # Número de baños","                num_banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"bathrooms\"}) else \"N/A\"","                ","                # Área (en mts²)","                mts2 = casa.find(\"p\", {\"data-test\": \"floor-area\"}).text.strip() if casa.find(\"p\", {\"data-test\": \"floor-area\"}) else \"N/A\"","                ","                # Escribir la fila de datos en el buffer CSV","                csv_writer.writerow([fecha_descarga, barrio, valor, num_habitaciones, num_banos, mts2])","            ","            except Exception as e:","                print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                continue","        ","        # Subir el CSV a S3 solo si hay datos","        if csv_buffer.getvalue().strip():  # Comprobar que el buffer tiene datos","            # Nombre del archivo CSV","            csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","            csv_key = csv_filename  # No se usa una carpeta","            ","            # Subir el CSV a S3","            s3_client.put_object(","                Bucket=target_bucket,","                Key=csv_key,","                Body=csv_buffer.getvalue(),","                ContentType=\"text/csv\"","            )","            print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        else:","            print(\"No se extrajeron datos de propiedades.\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":62},{"start":{"row":0,"column":0},"end":{"row":102,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Crear el buffer del CSV y el escritor","        csv_buffer = io.StringIO()  # Buffer en memoria para escribir el CSV","        csv_writer = csv.writer(csv_buffer)  # Crear el escritor para el CSV","        ","        # Escribir los encabezados en el archivo CSV","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])","        ","        # Extraer datos de cada apartamento","        for casa in soup.find_all(\"div\", class_=\"listing-card__content\"):","            try:","                # Fecha de descarga","                fecha_descarga = datetime.utcnow().strftime(\"%Y-%m-%d\")","                ","                # Barrio (Ubicación)","                barrio = casa.find(\"div\", class_=\"listing-card__location__geo\")","                barrio = barrio.text.strip() if barrio else \"N/A\"","                ","                # Precio (Valor)","                valor = casa.find(\"span\", class_=\"price__actual\")","                valor = valor.text.strip() if valor else \"N/A\"","                ","                # Número de habitaciones","                num_habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"})","                num_habitaciones = num_habitaciones.text.strip() if num_habitaciones else \"N/A\"","                ","                # Número de baños","                num_banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"})","                num_banos = num_banos.text.strip() if num_banos else \"N/A\"","                ","                # Área (en mts²)","                mts2 = casa.find(\"p\", {\"data-test\": \"floor-area\"})","                mts2 = mts2.text.strip() if mts2 else \"N/A\"","                ","                # Escribir la fila de datos en el buffer CSV","                csv_writer.writerow([fecha_descarga, barrio, valor, num_habitaciones, num_banos, mts2])","            ","            except Exception as e:","                print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                continue","        ","        # Subir el CSV a S3 solo si hay datos","        if csv_buffer.getvalue().strip():  # Comprobar que el buffer tiene datos","            # Nombre del archivo CSV","            csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","            csv_key = csv_filename  # No se usa una carpeta","            ","            # Subir el CSV a S3","            s3_client.put_object(","                Bucket=target_bucket,","                Key=csv_key,","                Body=csv_buffer.getvalue(),","                ContentType=\"text/csv\"","            )","            print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        else:","            print(\"No se extrajeron datos de propiedades.\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}],[{"start":{"row":0,"column":0},"end":{"row":102,"column":0},"action":"remove","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    ","    try:","        # Descargar el archivo desde S3","        response = s3_client.get_object(Bucket=bucket_origen, Key=archivo)","        html_content = response['Body'].read().decode(\"utf-8\")","        ","        # Procesar HTML con BeautifulSoup","        soup = BeautifulSoup(html_content, \"html.parser\")","        ","        # Crear el buffer del CSV y el escritor","        csv_buffer = io.StringIO()  # Buffer en memoria para escribir el CSV","        csv_writer = csv.writer(csv_buffer)  # Crear el escritor para el CSV","        ","        # Escribir los encabezados en el archivo CSV","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])","        ","        # Extraer datos de cada apartamento","        for casa in soup.find_all(\"div\", class_=\"listing-card__content\"):","            try:","                # Fecha de descarga","                fecha_descarga = datetime.utcnow().strftime(\"%Y-%m-%d\")","                ","                # Barrio (Ubicación)","                barrio = casa.find(\"div\", class_=\"listing-card__location__geo\")","                barrio = barrio.text.strip() if barrio else \"N/A\"","                ","                # Precio (Valor)","                valor = casa.find(\"span\", class_=\"price__actual\")","                valor = valor.text.strip() if valor else \"N/A\"","                ","                # Número de habitaciones","                num_habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"})","                num_habitaciones = num_habitaciones.text.strip() if num_habitaciones else \"N/A\"","                ","                # Número de baños","                num_banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"})","                num_banos = num_banos.text.strip() if num_banos else \"N/A\"","                ","                # Área (en mts²)","                mts2 = casa.find(\"p\", {\"data-test\": \"floor-area\"})","                mts2 = mts2.text.strip() if mts2 else \"N/A\"","                ","                # Escribir la fila de datos en el buffer CSV","                csv_writer.writerow([fecha_descarga, barrio, valor, num_habitaciones, num_banos, mts2])","            ","            except Exception as e:","                print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                continue","        ","        # Subir el CSV a S3 solo si hay datos","        if csv_buffer.getvalue().strip():  # Comprobar que el buffer tiene datos","            # Nombre del archivo CSV","            csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","            csv_key = csv_filename  # No se usa una carpeta","            ","            # Subir el CSV a S3","            s3_client.put_object(","                Bucket=target_bucket,","                Key=csv_key,","                Body=csv_buffer.getvalue(),","                ContentType=\"text/csv\"","            )","            print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        else:","            print(\"No se extrajeron datos de propiedades.\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""],"id":63},{"start":{"row":0,"column":0},"end":{"row":125,"column":0},"action":"insert","lines":["import json","import boto3","import csv","from bs4 import BeautifulSoup","from datetime import datetime","import io","","def lambda_handler(event, context):","    print(\"Evento recibido:\", json.dumps(event, indent=2))  # Depuración","    ","    # Verificar si \"Records\" está en event","    if \"Records\" not in event or not event[\"Records\"]:","        print(\"El evento no contiene 'Records'.\")","        return {","            \"statusCode\": 400,","            \"body\": \"Evento incorrecto. Se esperaba una notificación de S3.\"","        }","    ","    s3_client = boto3.client(\"s3\")","    bucket_origen = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]","    archivo = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]","    print(f\"Bucket de origen: {bucket_origen}, Archivo: {archivo}\")","    ","    target_bucket = \"paginaspruebas\"","    carpeta_origen = \"2025-03-10/\"  # Carpeta donde están los archivos HTML","    ","    try:","        # Crear el buffer del CSV y el escritor","        csv_buffer = io.StringIO()  # Buffer en memoria para escribir el CSV","        csv_writer = csv.writer(csv_buffer)  # Crear el escritor para el CSV","        ","        # Escribir los encabezados en el archivo CSV","        csv_writer.writerow([\"FechaDescarga\", \"Barrio\", \"Valor\", \"NumHabitaciones\", \"NumBanos\", \"mts2\"])","        ","        # Iterar sobre los archivos de las páginas","        page_number = 1  # Empezamos con la primera página","        while True:","            # Generar el nombre del archivo para cada página","            archivo_html = f\"{carpeta_origen}page_{page_number}.html\"","            print(f\"Procesando archivo: {archivo_html}\")","            ","            try:","                # Descargar el archivo HTML correspondiente","                response = s3_client.get_object(Bucket=bucket_origen, Key=archivo_html)","                html_content = response['Body'].read().decode(\"utf-8\")","                ","                # Parsear el HTML con BeautifulSoup","                soup = BeautifulSoup(html_content, \"html.parser\")","                ","                # Extraer los datos de las propiedades","                propiedades = soup.find_all(\"div\", class_=\"listing-card__content\")","                if not propiedades:","                    print(f\"No se encontraron propiedades en {archivo_html}, finalizando.\")","                    break  # Si no hay propiedades, se termina la iteración","                ","                # Procesar los datos de cada propiedad","                for casa in propiedades:","                    try:","                        # Fecha de descarga","                        fecha_descarga = datetime.utcnow().strftime(\"%Y-%m-%d\")","                        ","                        # Barrio (Ubicación)","                        barrio = casa.find(\"div\", class_=\"listing-card__location__geo\")","                        barrio = barrio.text.strip() if barrio else \"N/A\"","                        ","                        # Precio (Valor)","                        valor = casa.find(\"span\", class_=\"price__actual\")","                        valor = valor.text.strip() if valor else \"N/A\"","                        ","                        # Número de habitaciones","                        num_habitaciones = casa.find(\"p\", {\"data-test\": \"bedrooms\"})","                        num_habitaciones = num_habitaciones.text.strip() if num_habitaciones else \"N/A\"","                        ","                        # Número de baños","                        num_banos = casa.find(\"p\", {\"data-test\": \"bathrooms\"})","                        num_banos = num_banos.text.strip() if num_banos else \"N/A\"","                        ","                        # Área (en mts²)","                        mts2 = casa.find(\"p\", {\"data-test\": \"floor-area\"})","                        mts2 = mts2.text.strip() if mts2 else \"N/A\"","                        ","                        # Escribir la fila de datos en el buffer CSV","                        csv_writer.writerow([fecha_descarga, barrio, valor, num_habitaciones, num_banos, mts2])","                    ","                    except Exception as e:","                        print(f\"Error al extraer datos de una propiedad: {str(e)}\")","                        continue","                ","                # Aumentar el número de página","                page_number += 1","            ","            except s3_client.exceptions.NoSuchKey:","                # Si no existe el archivo, terminar el bucle","                print(f\"No se encontró el archivo {archivo_html}. Terminando proceso.\")","                break","","        # Subir el CSV a S3 solo si hay datos","        if csv_buffer.getvalue().strip():  # Comprobar que el buffer tiene datos","            # Nombre del archivo CSV","            csv_filename = f\"{datetime.utcnow().strftime('%Y-%m-%d')}.csv\"","            csv_key = csv_filename  # No se usa una carpeta","            ","            # Subir el CSV a S3","            s3_client.put_object(","                Bucket=target_bucket,","                Key=csv_key,","                Body=csv_buffer.getvalue(),","                ContentType=\"text/csv\"","            )","            print(f\"Archivo guardado en s3://{target_bucket}/{csv_key}\")","        ","        else:","            print(\"No se extrajeron datos de propiedades.\")","        ","        return {","            \"statusCode\": 200,","            \"body\": json.dumps(f\"Proceso completado. Datos guardados en {target_bucket}/{csv_key}\")","        }","    ","    except Exception as e:","        print(f\"Error procesando el archivo: {str(e)}\")","        return {","            \"statusCode\": 500,","            \"body\": json.dumps(f\"Error interno del servidor: {str(e)}\")","        }",""]}]]},"ace":{"folds":[],"scrolltop":120,"scrollleft":0,"selection":{"start":{"row":125,"column":0},"end":{"row":125,"column":0},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":{"row":7,"state":"start","mode":"ace/mode/python"}},"timestamp":1741600865300,"hash":"3ee1bf97759c3a5cdd6643dde0ad74b44fea337a"}